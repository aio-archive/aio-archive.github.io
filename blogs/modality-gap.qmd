---
title: Modality Gap
bibliography: ../assets/citation.bib
format:
  html:
    grid:
        body-width: 1400px
---

Paper compilation ([Email](mailto:quocviethere@gmail.com) me if you want to add other relevant papers that is not included.)


| Title | Year | Venue | Type |
|--------------------------------|----|-------|------|
|[Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning](https://papers.neurips.cc/paper_files/paper/2022/file/702f4db7543a7432431df588d57bc7c9-Paper-Conference.pdf#page=5.05) | 2022 | NeurIPS | <span class="badge bg-secondary">Fundamental</span> |
| [Explaining and Mitigating the Modality Gap in Contrastive Multimodal Learning](https://arxiv.org/pdf/2412.07909v1) | 2024 | arXiv | <span class="badge bg-warning">Theoretical</span> |
| [Two effects, one trigger: On the modality gap, object bias, and information imbalance in contrastive visionlanguage representation learning](https://arxiv.org/abs/2404.07983) | 2024 | arXiv | <span class="badge bg-warning">Theoretical</span> |
| [Towards understanding the modality gap in CLIP](https://openreview.net/forum?id=8W3KGzw7fNI) | 2024 | OpenReview | <span class="badge bg-warning">Theoretical</span> |
| [Itâ€™s not a modality gap: Characterizing and addressing the contrastive gap](https://arxiv.org/abs/2405.18570) | 2024 | arXiv | <span class="badge bg-warning">Theoretical</span> |
| [Bridge the Modality and Capability Gaps in Vision-Language Model Selection](https://openreview.net/pdf?id=01qa1ZJs65) | 2024 | OpenReview | <span class="badge bg-warning">Theoretical</span> |
| [Fill the Gap: Quantifying and Reducing the Modality Gap in Image-Text Representation Learning](https://arxiv.org/pdf/2505.03703) | 2025 | arXiv | <span class="badge bg-warning">Theoretical</span> |
| [Post-pre-training for Modality Alignment in Vision-Language Foundation Models](https://arxiv.org/abs/2504.12717) | 2025 | arXiv | <span class="badge bg-warning">Theoretical</span> |
| [Cross-Modal Mapping: Mitigating the Modality Gap for Few-Shot Image Classification](https://arxiv.org/abs/2412.20110) | 2024 | arXiv | <span class="badge bg-warning">Theoretical</span> |
| [Mitigating the Modality Gap: Few-Shot Out-of-Distribution Detection with Multi-modal Prototypes and Image Bias Estimation](https://arxiv.org/abs/2502.00662) | 2025 | arXiv | <span class="badge bg-warning">Theoretical</span> |
| [How to Bridge the Gap between Modalities: Survey on Multimodal Large Language Model](https://arxiv.org/abs/2311.07594) | 2023 | arXiv | <span class="badge bg-warning">Survey</span> |
| [Harnessing the Universal Geometry of Embeddings](https://arxiv.org/pdf/2505.12540) | 2025 | arXiv | <span class="badge bg-warning">Theoretical</span> |

# Blogs

- [Understanding and Comparing Latent Space Characteristics of Multi-Modal Models](https://www.journalovi.org/2024-humer-amumo/)


